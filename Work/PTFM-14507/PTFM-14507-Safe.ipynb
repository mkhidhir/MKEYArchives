{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d519420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© 1. Import necessary libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffec60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê 2. Set API endpoints and keys\n",
    "GRAPHQL_URL = \"https://api.kpler.marinetraffic.com/v2/vessels/graphql\"\n",
    "GRAPHQL_API_KEY = \"\"\n",
    "AIS_API_KEY = \"\"\n",
    "HISTORICAL_API_KEY = \"\"\n",
    "PORTCALLS_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7aa77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ 3. Fetch vessels by REGISTER_OWNER\n",
    "def fetch_vessels(after_cursor=None):\n",
    "    query = f\"\"\"\n",
    "    query Vessels {{\n",
    "        vessels(\n",
    "            first: 1000\n",
    "            where: {{\n",
    "                filters: [\n",
    "                    {{\n",
    "                        field: \"management.beneficialOwner.current.name\"\n",
    "                        op: LIKE\n",
    "                        values: [\"AASEN SHIPPING%\"]\n",
    "                    }}\n",
    "                ]\n",
    "                operator: OR\n",
    "            }}\n",
    "            after: {json.dumps(after_cursor)}\n",
    "        ) {{\n",
    "            nodes {{\n",
    "                identifier {{\n",
    "                    imo\n",
    "                }}\n",
    "            }}\n",
    "            pageInfo {{\n",
    "                hasNextPage\n",
    "                endCursor\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {GRAPHQL_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(GRAPHQL_URL, json={\"query\": query}, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d281ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 7 vessels. First 5 IMOs: [9060778, 9101546, 9147136, 9321407, 9433389]\n"
     ]
    }
   ],
   "source": [
    "# üì• 4. Loop through pages and gather IMO list\n",
    "imo_list = []\n",
    "after_cursor = None\n",
    "\n",
    "while True:\n",
    "    data = fetch_vessels(after_cursor)\n",
    "    if not data:\n",
    "        break\n",
    "\n",
    "    vessels = data[\"data\"][\"vessels\"][\"nodes\"]\n",
    "    for vessel in vessels:\n",
    "        imo = vessel[\"identifier\"].get(\"imo\")\n",
    "        if imo:\n",
    "            imo_list.append(imo)\n",
    "\n",
    "    page_info = data[\"data\"][\"vessels\"][\"pageInfo\"]\n",
    "    if page_info[\"hasNextPage\"]:\n",
    "        after_cursor = page_info[\"endCursor\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"‚úÖ Found {len(imo_list)} vessels. First 5 IMOs: {imo_list[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1f0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì° 5. Fetch live AIS positions from MT Export API\n",
    "def fetch_ais_data(api_key, imo_list, timespan=1440, buffer_time=1):\n",
    "    url_template = f'https://services.marinetraffic.com/api/exportvessel/{api_key}/v:6/timespan:{timespan}/imo:{{imo}}/protocol:jsono'\n",
    "    all_ais_data = []\n",
    "\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching AIS for IMO: {imo}\")\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list):\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "                        all_ais_data.append(record)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unexpected format for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed for IMO {imo}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)\n",
    "\n",
    "    if all_ais_data:\n",
    "        df = pd.DataFrame(all_ais_data)\n",
    "        if {'IMO', 'SHIPNAME', 'LAT', 'LON', 'TIMESTAMP'}.issubset(df.columns):\n",
    "            return df[['IMO', 'SHIPNAME', 'LAT', 'LON', 'TIMESTAMP']]\n",
    "        else:\n",
    "            return df\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No AIS data fetched.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c694fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Fetching AIS for IMO: 9060778\n",
      "[2/7] Fetching AIS for IMO: 9101546\n",
      "[3/7] Fetching AIS for IMO: 9147136\n",
      "[4/7] Fetching AIS for IMO: 9321407\n",
      "[5/7] Fetching AIS for IMO: 9433389\n",
      "[6/7] Fetching AIS for IMO: 9904766\n",
      "[7/7] Fetching AIS for IMO: 9904869\n",
      "‚úÖ Retrieved 7 AIS position records.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMO</th>\n",
       "      <th>SHIPNAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9060778</td>\n",
       "      <td>AASLI</td>\n",
       "      <td>54.613209</td>\n",
       "      <td>-5.916578</td>\n",
       "      <td>2025-05-08T08:17:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9101546</td>\n",
       "      <td>AASNES</td>\n",
       "      <td>54.391495</td>\n",
       "      <td>18.670176</td>\n",
       "      <td>2025-05-08T08:20:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9147136</td>\n",
       "      <td>AASTIND</td>\n",
       "      <td>53.680603</td>\n",
       "      <td>2.923402</td>\n",
       "      <td>2025-05-08T08:24:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9321407</td>\n",
       "      <td>AASTUN</td>\n",
       "      <td>59.640179</td>\n",
       "      <td>-0.178685</td>\n",
       "      <td>2025-05-08T08:22:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9433389</td>\n",
       "      <td>AASVIK</td>\n",
       "      <td>51.290115</td>\n",
       "      <td>-3.485885</td>\n",
       "      <td>2025-05-08T08:24:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IMO SHIPNAME        LAT        LON            TIMESTAMP\n",
       "0  9060778    AASLI  54.613209  -5.916578  2025-05-08T08:17:37\n",
       "1  9101546   AASNES  54.391495  18.670176  2025-05-08T08:20:34\n",
       "2  9147136  AASTIND  53.680603   2.923402  2025-05-08T08:24:05\n",
       "3  9321407   AASTUN  59.640179  -0.178685  2025-05-08T08:22:38\n",
       "4  9433389   AASVIK  51.290115  -3.485885  2025-05-08T08:24:17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîç 6. Call the function and show results\n",
    "df_ais = fetch_ais_data(AIS_API_KEY, imo_list)\n",
    "print(f\"‚úÖ Retrieved {len(df_ais)} AIS position records.\")\n",
    "df_ais.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9715210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data saved to: ais_positions_pdvsa_2025-05-08_16-25.csv\n"
     ]
    }
   ],
   "source": [
    "# üíæ 7. Save to CSV file\n",
    "if not df_ais.empty:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    output_filename = f\"ais_positions_pdvsa_{timestamp}.csv\"\n",
    "    df_ais.to_csv(output_filename, index=False)\n",
    "    print(f\"üìÅ Data saved to: {output_filename}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a181492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì° 8. Fetch and append historical AIS per IMO\n",
    "def fetch_historical_ais_and_save(api_key, imo_list, output_path, days=180, period=\"daily\", msgtype=\"simple\", buffer_time=60):\n",
    "    url_template = f'https://services.marinetraffic.com/api/exportvesseltrack/{api_key}/v:3/days:{days}/period:{period}/imo:{{imo}}/msgtype:{msgtype}/protocol:jsono'\n",
    "\n",
    "    # üßæ Create CSV with headers if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        with open(output_path, 'w', newline='') as f:\n",
    "            pd.DataFrame(columns=['IMO', 'LAT', 'LON', 'TIMESTAMP']).to_csv(f, index=False)\n",
    "\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching and saving AIS for IMO: {imo}\")\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and data:\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "                    df = pd.DataFrame(data)\n",
    "                    \n",
    "                    # ‚úçÔ∏è Save only if essential columns exist\n",
    "                    if {'IMO', 'LAT', 'LON', 'TIMESTAMP'}.issubset(df.columns):\n",
    "                        df[['IMO', 'LAT', 'LON', 'TIMESTAMP']].to_csv(output_path, mode='a', header=False, index=False)\n",
    "                        print(f\"‚úÖ Saved {len(df)} records for IMO {imo}\")\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Skipped saving due to missing fields for IMO {imo}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No data returned for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed request for IMO {imo}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)\n",
    "\n",
    "    # ‚úÖ Return final DataFrame\n",
    "    return pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "662702de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Fetching and saving AIS for IMO: 9060778\n",
      "‚úÖ Saved 181 records for IMO 9060778\n",
      "[2/7] Fetching and saving AIS for IMO: 9101546\n",
      "‚úÖ Saved 180 records for IMO 9101546\n",
      "[3/7] Fetching and saving AIS for IMO: 9147136\n",
      "‚úÖ Saved 181 records for IMO 9147136\n",
      "[4/7] Fetching and saving AIS for IMO: 9321407\n",
      "‚úÖ Saved 181 records for IMO 9321407\n",
      "[5/7] Fetching and saving AIS for IMO: 9433389\n",
      "‚úÖ Saved 181 records for IMO 9433389\n",
      "[6/7] Fetching and saving AIS for IMO: 9904766\n",
      "‚úÖ Saved 181 records for IMO 9904766\n",
      "[7/7] Fetching and saving AIS for IMO: 9904869\n",
      "‚úÖ Saved 180 records for IMO 9904869\n",
      "‚úÖ Retrieved 1265 historical AIS position records.\n",
      "üìÅ Historical AIS data confirmed saved to: historical_ais_pdvsa_2025-05-08_16-25.csv\n"
     ]
    }
   ],
   "source": [
    "# üîç 9. Call the historical AIS fetcher and preview\n",
    "output_hist_file = f\"historical_ais_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "df_hist_ais = fetch_historical_ais_and_save(\n",
    "    api_key=HISTORICAL_API_KEY,\n",
    "    imo_list=imo_list,\n",
    "    output_path=output_hist_file,\n",
    "    days=180,\n",
    "    period=\"daily\",\n",
    "    buffer_time=60\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Retrieved {len(df_hist_ais)} historical AIS position records.\")\n",
    "\n",
    "# üíæ 10. Already saved inside function, but you can log confirmation\n",
    "if not df_hist_ais.empty:\n",
    "    print(f\"üìÅ Historical AIS data confirmed saved to: {output_hist_file}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No historical data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d7906a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÜ 11. Derive dynamic date range from historical AIS DataFrame\n",
    "def get_dynamic_date_range(df_hist_ais):\n",
    "    if df_hist_ais.empty:\n",
    "        raise ValueError(\"üö´ Historical AIS DataFrame is empty. Cannot derive dynamic date range.\")\n",
    "\n",
    "    df_hist_ais['TIMESTAMP'] = pd.to_datetime(df_hist_ais['TIMESTAMP'], errors='coerce')\n",
    "    fromdate = df_hist_ais['TIMESTAMP'].min().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    todate = df_hist_ais['TIMESTAMP'].max().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print(f\"üìÜ Dynamic Date Range ‚Äî From: {fromdate} | To: {todate}\")\n",
    "    return fromdate, todate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9187448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß≠ 12. Fetch and append Port Calls using Port Calls API\n",
    "def fetch_port_calls_and_save(\n",
    "    api_key,\n",
    "    imo_list,\n",
    "    output_path,\n",
    "    df_hist_ais,\n",
    "    msgtype=\"simple\",\n",
    "    buffer_time=60\n",
    "):\n",
    "    # üéØ Get dynamic fromdate and todate\n",
    "    fromdate, todate = get_dynamic_date_range(df_hist_ais)\n",
    "\n",
    "    # üßæ Define required columns\n",
    "    required_columns = ['IMO', 'SHIPNAME', 'TIMESTAMP_UTC', 'MOVE_TYPE', 'PORT_ID', 'PORT_NAME']\n",
    "    \n",
    "    # üìÅ Ensure output CSV exists with headers\n",
    "    if not os.path.exists(output_path):\n",
    "        pd.DataFrame(columns=required_columns).to_csv(output_path, index=False)\n",
    "        print(f\"üìÑ Created new CSV file with headers: {output_path}\")\n",
    "    \n",
    "    url_template = (\n",
    "        f'https://services.marinetraffic.com/api/portcalls/{api_key}/v:6/'\n",
    "        f'fromdate:{fromdate}/todate:{todate}/imo:{{imo}}/msgtype:{msgtype}/protocol:jsono'\n",
    "    )\n",
    "\n",
    "    # üöÄ Loop through each IMO\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching Port Calls for IMO: {imo}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and data:\n",
    "                    # üè∑Ô∏è Tag records with IMO\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "                    \n",
    "                    df = pd.DataFrame(data)\n",
    "\n",
    "                    # ‚úÖ Save if valid\n",
    "                    if set(required_columns).issubset(df.columns):\n",
    "                        df[required_columns].to_csv(output_path, mode='a', header=False, index=False)\n",
    "                        print(f\"‚úÖ Saved {len(df)} port call records for IMO {imo}\")\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Missing required fields ‚Äî skipped saving for IMO {imo}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No port call data for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed request for IMO {imo}: {response.status_code}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        # ‚è±Ô∏è Pause between calls to respect rate limits\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c6fbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÜ Dynamic Date Range ‚Äî From: 2024-11-09 08:42 | To: 2025-05-08 02:33\n",
      "üìÑ Created new CSV file with headers: port_calls_pdvsa_2025-05-08_16-31.csv\n",
      "[1/7] Fetching Port Calls for IMO: 9060778\n",
      "‚úÖ Saved 193 port call records for IMO 9060778\n",
      "[2/7] Fetching Port Calls for IMO: 9101546\n",
      "‚úÖ Saved 177 port call records for IMO 9101546\n",
      "[3/7] Fetching Port Calls for IMO: 9147136\n",
      "‚úÖ Saved 158 port call records for IMO 9147136\n",
      "[4/7] Fetching Port Calls for IMO: 9321407\n",
      "‚úÖ Saved 272 port call records for IMO 9321407\n",
      "[5/7] Fetching Port Calls for IMO: 9433389\n",
      "‚úÖ Saved 316 port call records for IMO 9433389\n",
      "[6/7] Fetching Port Calls for IMO: 9904766\n",
      "‚úÖ Saved 150 port call records for IMO 9904766\n",
      "[7/7] Fetching Port Calls for IMO: 9904869\n",
      "‚úÖ Saved 199 port call records for IMO 9904869\n"
     ]
    }
   ],
   "source": [
    "# üìÅ 13. Output file path\n",
    "output_csv = f\"port_calls_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "\n",
    "# üì° 14. Run the fetcher with dynamic dates\n",
    "fetch_port_calls_and_save(\n",
    "    api_key=PORTCALLS_API_KEY,\n",
    "    imo_list=imo_list,\n",
    "    output_path=output_csv,\n",
    "    df_hist_ais=df_hist_ais,  # Pass in the historical AIS dataframe\n",
    "    buffer_time=60  # ‚è≥ Adjustable delay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Combining files:\n",
      "- ais_positions_pdvsa_2025-05-08_16-25.csv\n",
      "- historical_ais_pdvsa_2025-05-08_16-25.csv\n",
      "- port_calls_pdvsa_2025-05-08_16-31.csv\n",
      "‚úÖ Enriched dataset saved to: combined_ais_pdvsa_2025-05-08_16-37.csv\n"
     ]
    }
   ],
   "source": [
    "# üß™ 15. Combine and Enrich All Datasets\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "def combine_and_enrich_datasets():\n",
    "    # üìÇ Find latest files dynamically\n",
    "    latest_ais = sorted(glob(\"ais_positions_pdvsa_*.csv\"))[-1]\n",
    "    latest_hist = sorted(glob(\"historical_ais_pdvsa_*.csv\"))[-1]\n",
    "    latest_ports = sorted(glob(\"port_calls_pdvsa_*.csv\"))[-1]\n",
    "\n",
    "    print(f\"üîÑ Combining files:\\n- {latest_ais}\\n- {latest_hist}\\n- {latest_ports}\")\n",
    "\n",
    "    # üìñ Load datasets\n",
    "    df_live = pd.read_csv(latest_ais, parse_dates=[\"TIMESTAMP\"])\n",
    "    df_hist = pd.read_csv(latest_hist, parse_dates=[\"TIMESTAMP\"])\n",
    "    df_ports = pd.read_csv(latest_ports, parse_dates=[\"TIMESTAMP_UTC\"])\n",
    "\n",
    "    # üßÆ Combine live + historical AIS\n",
    "    df_all_positions = pd.concat([df_live, df_hist], ignore_index=True)\n",
    "    df_all_positions.sort_values(by=[\"IMO\", \"TIMESTAMP\"], inplace=True)\n",
    "\n",
    "    # üß† Add LAST_PORT and NEXT_PORT columns\n",
    "    df_all_positions[\"LAST_PORT\"] = None\n",
    "    df_all_positions[\"LAST_PORT_ID\"] = None\n",
    "    df_all_positions[\"NEXT_PORT\"] = None\n",
    "    df_all_positions[\"NEXT_PORT_ID\"] = None\n",
    "\n",
    "    # üîó Match each AIS row to port calls\n",
    "    for imo in df_all_positions[\"IMO\"].unique():\n",
    "        df_ais_vessel = df_all_positions[df_all_positions[\"IMO\"] == imo]\n",
    "        df_ports_vessel = df_ports[df_ports[\"IMO\"] == imo]\n",
    "\n",
    "        for idx, ais_row in df_ais_vessel.iterrows():\n",
    "            position_time = ais_row[\"TIMESTAMP\"]\n",
    "\n",
    "            # Match Departure (LAST_PORT)\n",
    "            departures = df_ports_vessel[\n",
    "                (df_ports_vessel[\"MOVE_TYPE\"] == 1) &\n",
    "                (df_ports_vessel[\"TIMESTAMP_UTC\"] <= position_time)\n",
    "            ]\n",
    "            if not departures.empty:\n",
    "                last_dep = departures.sort_values(by=\"TIMESTAMP_UTC\").iloc[-1]\n",
    "                df_all_positions.at[idx, \"LAST_PORT\"] = last_dep[\"PORT_NAME\"]\n",
    "                df_all_positions.at[idx, \"LAST_PORT_ID\"] = last_dep[\"PORT_ID\"]\n",
    "\n",
    "            # Match Arrival (NEXT_PORT)\n",
    "            arrivals = df_ports_vessel[\n",
    "                (df_ports_vessel[\"MOVE_TYPE\"] == 0) &\n",
    "                (df_ports_vessel[\"TIMESTAMP_UTC\"] >= position_time)\n",
    "            ]\n",
    "            if not arrivals.empty:\n",
    "                next_arr = arrivals.sort_values(by=\"TIMESTAMP_UTC\").iloc[0]\n",
    "                df_all_positions.at[idx, \"NEXT_PORT\"] = next_arr[\"PORT_NAME\"]\n",
    "                df_all_positions.at[idx, \"NEXT_PORT_ID\"] = next_arr[\"PORT_ID\"]\n",
    "\n",
    "    # üíæ Save enriched data\n",
    "    output_name = f\"combined_ais_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "    df_all_positions.to_csv(output_name, index=False)\n",
    "    print(f\"‚úÖ Enriched dataset saved to: {output_name}\")\n",
    "\n",
    "# üß† Run the combining process\n",
    "combine_and_enrich_datasets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
