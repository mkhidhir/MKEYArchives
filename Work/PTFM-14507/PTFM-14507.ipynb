{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d519420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© 1. Import necessary libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dffec60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê 2. Set API endpoints and keys\n",
    "GRAPHQL_URL = \"https://api.kpler.marinetraffic.com/v2/vessels/graphql\"\n",
    "GRAPHQL_API_KEY = \"RTZCQWF2ZHJpWWVheXJZTmZIenFNRXFzZTQzdDNaUEQ6MU1vZ0dqWUQtZHFMMXNTMnNER21CZzNzSjcyUUdzQ0hfSHBFWlFRTk9pT2NwVWpzeF9TclZ0QzNvU0NwMlJpQg==\"\n",
    "AIS_API_KEY = \"9fefb8446c56fb0a729888d02f87476e4aed1b1d\"\n",
    "HISTORICAL_API_KEY = \"5299b468cfb79b872d52de2e7d76cb0d7aae5d38\"\n",
    "PORTCALLS_API_KEY = \"466dfc66648fd8ee1d6e282c160100439653a463\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7aa77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ 3. Fetch vessels by REGISTER_OWNER\n",
    "def fetch_vessels(after_cursor=None):\n",
    "    query = f\"\"\"\n",
    "    query Vessels {{\n",
    "        vessels(\n",
    "            first: 1000\n",
    "            where: {{\n",
    "                filters: [\n",
    "                    {{\n",
    "                        field: \"management.beneficialOwner.current.name\"\n",
    "                        op: LIKE\n",
    "                        values: [\"AASEN SHIPPING%\"]\n",
    "                    }}\n",
    "                ]\n",
    "                operator: OR\n",
    "            }}\n",
    "            after: {json.dumps(after_cursor)}\n",
    "        ) {{\n",
    "            nodes {{\n",
    "                identifier {{\n",
    "                    imo\n",
    "                }}\n",
    "            }}\n",
    "            pageInfo {{\n",
    "                hasNextPage\n",
    "                endCursor\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {GRAPHQL_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(GRAPHQL_URL, json={\"query\": query}, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d281ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 7 vessels. First 5 IMOs: [9060778, 9101546, 9147136, 9321407, 9433389]\n"
     ]
    }
   ],
   "source": [
    "# üì• 4. Loop through pages and gather IMO list\n",
    "imo_list = []\n",
    "after_cursor = None\n",
    "\n",
    "while True:\n",
    "    data = fetch_vessels(after_cursor)\n",
    "    if not data:\n",
    "        break\n",
    "\n",
    "    vessels = data[\"data\"][\"vessels\"][\"nodes\"]\n",
    "    for vessel in vessels:\n",
    "        imo = vessel[\"identifier\"].get(\"imo\")\n",
    "        if imo:\n",
    "            imo_list.append(imo)\n",
    "\n",
    "    page_info = data[\"data\"][\"vessels\"][\"pageInfo\"]\n",
    "    if page_info[\"hasNextPage\"]:\n",
    "        after_cursor = page_info[\"endCursor\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"‚úÖ Found {len(imo_list)} vessels. First 5 IMOs: {imo_list[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f1f0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì° 5. Fetch live AIS positions from MT Export API\n",
    "def fetch_ais_data(api_key, imo_list, timespan=1440, buffer_time=1):\n",
    "    url_template = f'https://services.marinetraffic.com/api/exportvessel/{api_key}/v:6/timespan:{timespan}/imo:{{imo}}/protocol:jsono'\n",
    "    all_ais_data = []\n",
    "\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching AIS for IMO: {imo}\")\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list):\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "                        all_ais_data.append(record)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unexpected format for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed for IMO {imo}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)\n",
    "\n",
    "    if all_ais_data:\n",
    "        df = pd.DataFrame(all_ais_data)\n",
    "        if {'IMO', 'SHIPNAME', 'LAT', 'LON', 'TIMESTAMP'}.issubset(df.columns):\n",
    "            return df[['IMO', 'SHIPNAME', 'LAT', 'LON', 'TIMESTAMP']]\n",
    "        else:\n",
    "            return df\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No AIS data fetched.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c694fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Fetching AIS for IMO: 9060778\n",
      "[2/7] Fetching AIS for IMO: 9101546\n",
      "[3/7] Fetching AIS for IMO: 9147136\n",
      "[4/7] Fetching AIS for IMO: 9321407\n",
      "[5/7] Fetching AIS for IMO: 9433389\n",
      "[6/7] Fetching AIS for IMO: 9904766\n",
      "[7/7] Fetching AIS for IMO: 9904869\n",
      "‚úÖ Retrieved 7 AIS position records.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMO</th>\n",
       "      <th>SHIPNAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9060778</td>\n",
       "      <td>AASLI</td>\n",
       "      <td>54.049202</td>\n",
       "      <td>-3.166848</td>\n",
       "      <td>2025-05-21T05:02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9101546</td>\n",
       "      <td>AASNES</td>\n",
       "      <td>55.719112</td>\n",
       "      <td>12.633556</td>\n",
       "      <td>2025-05-21T05:01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9147136</td>\n",
       "      <td>AASTIND</td>\n",
       "      <td>51.313572</td>\n",
       "      <td>3.831798</td>\n",
       "      <td>2025-05-21T05:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9321407</td>\n",
       "      <td>AASTUN</td>\n",
       "      <td>54.095207</td>\n",
       "      <td>11.114382</td>\n",
       "      <td>2025-05-21T05:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9433389</td>\n",
       "      <td>AASVIK</td>\n",
       "      <td>51.467525</td>\n",
       "      <td>0.257450</td>\n",
       "      <td>2025-05-21T04:59:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IMO SHIPNAME        LAT        LON            TIMESTAMP\n",
       "0  9060778    AASLI  54.049202  -3.166848  2025-05-21T05:02:13\n",
       "1  9101546   AASNES  55.719112  12.633556  2025-05-21T05:01:55\n",
       "2  9147136  AASTIND  51.313572   3.831798  2025-05-21T05:00:10\n",
       "3  9321407   AASTUN  54.095207  11.114382  2025-05-21T05:01:20\n",
       "4  9433389   AASVIK  51.467525   0.257450  2025-05-21T04:59:44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîç 6. Call the function and show results\n",
    "df_ais = fetch_ais_data(AIS_API_KEY, imo_list)\n",
    "print(f\"‚úÖ Retrieved {len(df_ais)} AIS position records.\")\n",
    "df_ais.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9715210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data saved to: ais_positions_pdvsa_2025-05-21_13-04.csv\n"
     ]
    }
   ],
   "source": [
    "# üíæ 7. Save to CSV file\n",
    "if not df_ais.empty:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    output_filename = f\"ais_positions_pdvsa_{timestamp}.csv\"\n",
    "    df_ais.to_csv(output_filename, index=False)\n",
    "    print(f\"üìÅ Data saved to: {output_filename}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a181492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì° 8. Fetch and append historical AIS per IMO\n",
    "def fetch_historical_ais_and_save(api_key, imo_list, output_path, days=180, period=\"daily\", msgtype=\"simple\", buffer_time=60):\n",
    "    url_template = f'https://services.marinetraffic.com/api/exportvesseltrack/{api_key}/v:3/days:{days}/period:{period}/imo:{{imo}}/msgtype:{msgtype}/protocol:jsono'\n",
    "\n",
    "    # üßæ Create CSV with headers if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        with open(output_path, 'w', newline='') as f:\n",
    "            pd.DataFrame(columns=['IMO', 'LAT', 'LON', 'TIMESTAMP']).to_csv(f, index=False)\n",
    "\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching and saving AIS for IMO: {imo}\")\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and data:\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "                    df = pd.DataFrame(data)\n",
    "                    \n",
    "                    # ‚úçÔ∏è Save only if essential columns exist\n",
    "                    if {'IMO', 'LAT', 'LON', 'TIMESTAMP'}.issubset(df.columns):\n",
    "                        df[['IMO', 'LAT', 'LON', 'TIMESTAMP']].to_csv(output_path, mode='a', header=False, index=False)\n",
    "                        print(f\"‚úÖ Saved {len(df)} records for IMO {imo}\")\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Skipped saving due to missing fields for IMO {imo}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No data returned for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed request for IMO {imo}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)\n",
    "\n",
    "    # ‚úÖ Return final DataFrame\n",
    "    return pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "662702de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Fetching and saving AIS for IMO: 9060778\n",
      "‚úÖ Saved 181 records for IMO 9060778\n",
      "[2/7] Fetching and saving AIS for IMO: 9101546\n",
      "‚úÖ Saved 180 records for IMO 9101546\n",
      "[3/7] Fetching and saving AIS for IMO: 9147136\n",
      "‚úÖ Saved 181 records for IMO 9147136\n",
      "[4/7] Fetching and saving AIS for IMO: 9321407\n",
      "‚úÖ Saved 181 records for IMO 9321407\n",
      "[5/7] Fetching and saving AIS for IMO: 9433389\n",
      "‚úÖ Saved 181 records for IMO 9433389\n",
      "[6/7] Fetching and saving AIS for IMO: 9904766\n",
      "‚úÖ Saved 181 records for IMO 9904766\n",
      "[7/7] Fetching and saving AIS for IMO: 9904869\n",
      "‚úÖ Saved 181 records for IMO 9904869\n",
      "‚úÖ Retrieved 1266 historical AIS position records.\n",
      "üìÅ Historical AIS data confirmed saved to: historical_ais_pdvsa_2025-05-21_13-04.csv\n"
     ]
    }
   ],
   "source": [
    "# üîç 9. Call the historical AIS fetcher and preview\n",
    "output_hist_file = f\"historical_ais_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "df_hist_ais = fetch_historical_ais_and_save(\n",
    "    api_key=HISTORICAL_API_KEY,\n",
    "    imo_list=imo_list,\n",
    "    output_path=output_hist_file,\n",
    "    days=180,\n",
    "    period=\"daily\",\n",
    "    buffer_time=60\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Retrieved {len(df_hist_ais)} historical AIS position records.\")\n",
    "\n",
    "# üíæ 10. Already saved inside function, but you can log confirmation\n",
    "if not df_hist_ais.empty:\n",
    "    print(f\"üìÅ Historical AIS data confirmed saved to: {output_hist_file}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No historical data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d7906a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÜ 11. Derive dynamic date range from historical AIS DataFrame\n",
    "def get_dynamic_date_range(df_hist_ais):\n",
    "    if df_hist_ais.empty:\n",
    "        raise ValueError(\"üö´ Historical AIS DataFrame is empty. Cannot derive dynamic date range.\")\n",
    "\n",
    "    df_hist_ais['TIMESTAMP'] = pd.to_datetime(df_hist_ais['TIMESTAMP'], errors='coerce')\n",
    "    fromdate = df_hist_ais['TIMESTAMP'].min().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    todate = df_hist_ais['TIMESTAMP'].max().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print(f\"üìÜ Dynamic Date Range ‚Äî From: {fromdate} | To: {todate}\")\n",
    "    return fromdate, todate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9187448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_port_calls_and_save(\n",
    "    api_key,\n",
    "    imo_list,\n",
    "    output_path,\n",
    "    df_hist_ais,\n",
    "    msgtype=\"extended\",\n",
    "    buffer_time=120\n",
    "):\n",
    "    fromdate, todate = get_dynamic_date_range(df_hist_ais)\n",
    "\n",
    "    # Add LOAD_STATUS to required columns\n",
    "    required_columns = ['IMO', 'SHIPNAME', 'TIMESTAMP_UTC', 'MOVE_TYPE', 'PORT_ID', 'PORT_NAME', 'LOAD_STATUS']\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        pd.DataFrame(columns=required_columns).to_csv(output_path, index=False)\n",
    "        print(f\"üìÑ Created new CSV file with headers: {output_path}\")\n",
    "\n",
    "    url_template = (\n",
    "        f'https://services.marinetraffic.com/api/portcalls/{api_key}/v:6/'\n",
    "        f'fromdate:{fromdate}/todate:{todate}/imo:{{imo}}/msgtype:{msgtype}/protocol:jsono'\n",
    "    )\n",
    "\n",
    "    load_status_map = {\n",
    "        0: \"N/A\",\n",
    "        1: \"In Ballast\",\n",
    "        2: \"Partially Laden\",\n",
    "        3: \"Fully Laden\"\n",
    "    }\n",
    "\n",
    "    for idx, imo in enumerate(imo_list, start=1):\n",
    "        print(f\"[{idx}/{len(imo_list)}] Fetching Port Calls for IMO: {imo}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url_template.format(imo=imo))\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and data:\n",
    "                    for record in data:\n",
    "                        record['IMO'] = imo\n",
    "\n",
    "                        # Normalize raw_status safely:\n",
    "                        raw_status = record.get('LOAD_STATUS', 0)\n",
    "\n",
    "                        # Attempt to convert to int, fallback to 0\n",
    "                        try:\n",
    "                            raw_status_int = int(raw_status)\n",
    "                        except (ValueError, TypeError):\n",
    "                            raw_status_int = 0\n",
    "\n",
    "                        # Map to human-readable string\n",
    "                        record['LOAD_STATUS'] = load_status_map.get(raw_status_int, \"N/A\")\n",
    "\n",
    "                    df = pd.DataFrame(data)\n",
    "\n",
    "                    if set(required_columns).issubset(df.columns):\n",
    "                        df[required_columns].to_csv(output_path, mode='a', header=False, index=False)\n",
    "                        print(f\"‚úÖ Saved {len(df)} port call records for IMO {imo}\")\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Missing required fields ‚Äî skipped saving for IMO {imo}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No port call data for IMO {imo}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed request for IMO {imo}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception for IMO {imo}: {e}\")\n",
    "\n",
    "        if idx < len(imo_list):\n",
    "            time.sleep(buffer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c6fbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÜ Dynamic Date Range ‚Äî From: 2024-11-22 05:13 | To: 2025-05-21 00:54\n",
      "üìÑ Created new CSV file with headers: port_calls_pdvsa_2025-05-21_13-10.csv\n",
      "[1/7] Fetching Port Calls for IMO: 9060778\n",
      "‚úÖ Saved 196 port call records for IMO 9060778\n",
      "[2/7] Fetching Port Calls for IMO: 9101546\n",
      "‚úÖ Saved 175 port call records for IMO 9101546\n",
      "[3/7] Fetching Port Calls for IMO: 9147136\n",
      "‚úÖ Saved 174 port call records for IMO 9147136\n",
      "[4/7] Fetching Port Calls for IMO: 9321407\n",
      "‚úÖ Saved 266 port call records for IMO 9321407\n",
      "[5/7] Fetching Port Calls for IMO: 9433389\n",
      "‚úÖ Saved 304 port call records for IMO 9433389\n",
      "[6/7] Fetching Port Calls for IMO: 9904766\n",
      "‚úÖ Saved 149 port call records for IMO 9904766\n",
      "[7/7] Fetching Port Calls for IMO: 9904869\n",
      "‚úÖ Saved 199 port call records for IMO 9904869\n"
     ]
    }
   ],
   "source": [
    "# üìÅ 13. Output file path\n",
    "output_csv = f\"port_calls_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "\n",
    "# üì° 14. Run the fetcher with dynamic dates\n",
    "fetch_port_calls_and_save(\n",
    "    api_key=PORTCALLS_API_KEY,\n",
    "    imo_list=imo_list,\n",
    "    output_path=output_csv,\n",
    "    df_hist_ais=df_hist_ais,  # Pass in the historical AIS dataframe\n",
    "    buffer_time=60  # ‚è≥ Adjustable delay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ca2d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Combining files:\n",
      "- ais_positions_pdvsa_2025-05-21_13-04.csv\n",
      "- historical_ais_pdvsa_2025-05-21_13-04.csv\n",
      "- port_calls_pdvsa_2025-05-21_13-10.csv\n",
      "‚úÖ Enriched dataset saved to: combined_ais_pdvsa_2025-05-21_13-46.csv\n"
     ]
    }
   ],
   "source": [
    "# 15. Combine and Enrich All Datasets\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def combine_and_enrich_datasets():\n",
    "    latest_ais = sorted(glob(\"ais_positions_pdvsa_*.csv\"))[-1]\n",
    "    latest_hist = sorted(glob(\"historical_ais_pdvsa_*.csv\"))[-1]\n",
    "    latest_ports = sorted(glob(\"port_calls_pdvsa_*.csv\"))[-1]\n",
    "\n",
    "    print(f\"üîÑ Combining files:\\n- {latest_ais}\\n- {latest_hist}\\n- {latest_ports}\")\n",
    "\n",
    "    df_live = pd.read_csv(latest_ais, parse_dates=[\"TIMESTAMP\"])\n",
    "    df_hist = pd.read_csv(latest_hist, parse_dates=[\"TIMESTAMP\"])\n",
    "    df_ports = pd.read_csv(latest_ports, parse_dates=[\"TIMESTAMP_UTC\"])\n",
    "\n",
    "    # Combine live and historical AIS data\n",
    "    df_all_positions = pd.concat([df_live, df_hist], ignore_index=True)\n",
    "    df_all_positions.sort_values(by=[\"IMO\", \"TIMESTAMP\"], inplace=True)\n",
    "\n",
    "    # üîß Fix missing SHIPNAME: Prefer from AIS, fallback to port_calls\n",
    "    if \"SHIPNAME\" not in df_all_positions.columns:\n",
    "        df_all_positions[\"SHIPNAME\"] = None\n",
    "\n",
    "    # Fill SHIPNAME using AIS data grouped by IMO\n",
    "    df_all_positions[\"SHIPNAME\"] = df_all_positions.groupby(\"IMO\")[\"SHIPNAME\"].transform(\n",
    "        lambda x: x.ffill().bfill()\n",
    "    )\n",
    "\n",
    "    # Fallback: use SHIPNAME from port_calls if still missing\n",
    "    if \"SHIPNAME\" in df_ports.columns:\n",
    "        missing_names = df_all_positions[\"SHIPNAME\"].isna()\n",
    "        df_all_positions.loc[missing_names, \"SHIPNAME\"] = (\n",
    "            df_all_positions[missing_names]\n",
    "            .merge(df_ports[[\"IMO\", \"SHIPNAME\"]].dropna().drop_duplicates(), on=\"IMO\", how=\"left\")[\"SHIPNAME_y\"]\n",
    "        )\n",
    "\n",
    "    # üß† Add enrichment columns\n",
    "    df_all_positions[\"LAST_PORT\"] = None\n",
    "    df_all_positions[\"LAST_PORT_ID\"] = None\n",
    "    df_all_positions[\"LAST_PORT_OP\"] = None\n",
    "    df_all_positions[\"NEXT_PORT\"] = None\n",
    "    df_all_positions[\"NEXT_PORT_ID\"] = None\n",
    "    df_all_positions[\"NEXT_PORT_OP\"] = None\n",
    "\n",
    "    for imo in df_all_positions[\"IMO\"].unique():\n",
    "        df_ais_vessel = df_all_positions[df_all_positions[\"IMO\"] == imo]\n",
    "        df_ports_vessel = df_ports[df_ports[\"IMO\"] == imo]\n",
    "\n",
    "        for idx, ais_row in df_ais_vessel.iterrows():\n",
    "            position_time = ais_row[\"TIMESTAMP\"]\n",
    "\n",
    "            # Match Departure (LAST_PORT)\n",
    "            departures = df_ports_vessel[\n",
    "                (df_ports_vessel[\"MOVE_TYPE\"] == 1) &\n",
    "                (df_ports_vessel[\"TIMESTAMP_UTC\"] <= position_time)\n",
    "            ]\n",
    "            if not departures.empty:\n",
    "                last_dep = departures.sort_values(by=\"TIMESTAMP_UTC\").iloc[-1]\n",
    "                df_all_positions.at[idx, \"LAST_PORT\"] = last_dep[\"PORT_NAME\"]\n",
    "                df_all_positions.at[idx, \"LAST_PORT_ID\"] = last_dep[\"PORT_ID\"]\n",
    "                df_all_positions.at[idx, \"LAST_PORT_OP\"] = last_dep.get(\"LOAD_STATUS\", \"NA\")\n",
    "\n",
    "            # Match Arrival (NEXT_PORT)\n",
    "            arrivals = df_ports_vessel[\n",
    "                (df_ports_vessel[\"MOVE_TYPE\"] == 0) &\n",
    "                (df_ports_vessel[\"TIMESTAMP_UTC\"] >= position_time)\n",
    "            ]\n",
    "            if not arrivals.empty:\n",
    "                next_arr = arrivals.sort_values(by=\"TIMESTAMP_UTC\").iloc[0]\n",
    "                df_all_positions.at[idx, \"NEXT_PORT\"] = next_arr[\"PORT_NAME\"]\n",
    "                df_all_positions.at[idx, \"NEXT_PORT_ID\"] = next_arr[\"PORT_ID\"]\n",
    "                df_all_positions.at[idx, \"NEXT_PORT_OP\"] = next_arr.get(\"LOAD_STATUS\", \"NA\")\n",
    "\n",
    "    output_name = f\"combined_ais_pdvsa_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "    df_all_positions.to_csv(output_name, index=False)\n",
    "    print(f\"‚úÖ Enriched dataset saved to: {output_name}\")\n",
    "\n",
    "# üß† Run the combining process\n",
    "combine_and_enrich_datasets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
